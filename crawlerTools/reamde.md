## 编写的起点

> 无论是工作中或个人在生活中遇到想要获取的网络数据，使用python爬虫是一种很常见的效率方法。以前在学校时尝试使用过node爬虫，之前有段时间也接触过油猴插件，觉得应该也挺方便的，主要不知道是否可以对文件进行操作。不过，最近python用的比较多，所以还是整理一个使用python selenium的一个简单工具模板

环境准备

- google driver，去google查看自己的版本找到对应的driver进行下载如果没有version一模一样的下载最接近的
- google插件xpath helper，在获取元素定位时该插件是一大利器啊，比F12开发工具好用，没有尝试过获取动态的那种元素（ps：这种元素点一下开发工具的检查元素就没有了，一般是这种`::before`这类伪元素
- python包selenium，pandas（由于数据后面需要处理，一般我们会写到一张表格里比如excel比较常用，使用pandas方便很多

```sh
pip install selenium
pip install pandas
```

关于数据处理，我之前想的是存入一个json文件然后转成excel，最后发现如果json层级太多了，转换的时候自己写逻辑根本绕不过来，也没有发现很好的模板或是工具，最后还是写到一个txt文件中，最后读取txt构成这样一个list

```python
as_list = [
  {"表头1":"a", "表头2": "b"},
  {"表头1":"c", "表头2": "d"},
  {"表头1":"a", "表头2": "k"},
]
```

| 表头1 | 表头2 |
| :---: | :---: |
|   a   |   b   |
|   c   |   d   |
|   a   |   k   |

至于第一行和第二行需要合并一起的操作就交给python额外写逻辑处理，或是直接使用excel中工具方法合并

之前想法是能够这样一个json

```json
{
  "a":["b","k"],
  "c":["d"],
}
```

当然实际的层级复杂的多，我理想的认为很容易找到工具转换成一个优美的表格。但却没有找到
